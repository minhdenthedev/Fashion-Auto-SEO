{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d042d0e",
   "metadata": {
    "id": "7gshOXlq9d69",
    "papermill": {
     "duration": 0.003395,
     "end_time": "2025-03-08T07:52:35.811330",
     "exception": false,
     "start_time": "2025-03-08T07:52:35.807935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Prepare python script for running dual GPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb31b5bf",
   "metadata": {
    "papermill": {
     "duration": 0.002618,
     "end_time": "2025-03-08T07:52:35.817042",
     "exception": false,
     "start_time": "2025-03-08T07:52:35.814424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Prepare dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d0824",
   "metadata": {
    "id": "8LIUaoLUl5HD",
    "papermill": {
     "duration": 0.00263,
     "end_time": "2025-03-08T07:52:35.822423",
     "exception": false,
     "start_time": "2025-03-08T07:52:35.819793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Images after preprocessing:\n",
    "- Remove noisy images\n",
    "- Cropping using YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395fc7ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T07:52:35.828790Z",
     "iopub.status.busy": "2025-03-08T07:52:35.828551Z",
     "iopub.status.idle": "2025-03-08T07:52:35.834513Z",
     "shell.execute_reply": "2025-03-08T07:52:35.833758Z"
    },
    "id": "aVyS5GFY9fJH",
    "papermill": {
     "duration": 0.010505,
     "end_time": "2025-03-08T07:52:35.835693",
     "exception": false,
     "start_time": "2025-03-08T07:52:35.825188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dataset_loading.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset_loading.py\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "  def __init__(self, image_dir):\n",
    "    \"\"\"\n",
    "      image_dir=/content/drive/MyDrive/data\n",
    "      image_dir\n",
    "          |____ ao_hoodie_nam\n",
    "          |____ ao_lien_quan\n",
    "          ......\n",
    "          |____ trung_nien_nu\n",
    "    \"\"\"\n",
    "    self.image_dir = image_dir\n",
    "\n",
    "    # read image and load label\n",
    "    self.categories = sorted([folder for folder in os.listdir(image_dir) if folder != 'quan_ao_nam_trung_nien'])\n",
    "    labels = {k:v for k, v in zip(self.categories, range(len(self.categories)))}\n",
    "    self.num_classes = len(self.categories)\n",
    "    self.images = []\n",
    "    self.labels = []\n",
    "    for category in self.categories:\n",
    "      image_files = [f for f in os.listdir(os.path.join(image_dir, category)) if f.endswith(('.jpg', '.png'))]\n",
    "      self.images.extend(image_files)\n",
    "      self.labels.extend([labels[category]]*len(image_files))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    img_file = self.images[idx]\n",
    "    label = self.labels[idx]\n",
    "    category = self.categories[label]\n",
    "    img = Image.open(os.path.join(self.image_dir, category, img_file)).convert('RGB')\n",
    "    return img, label\n",
    "\n",
    "class TransformedDataset(Dataset):\n",
    "  def __init__(self, subset, transform=None):\n",
    "    self.subset = subset\n",
    "    if not transform:\n",
    "      self.transform = transforms.ToTensor()\n",
    "    else:\n",
    "      self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.subset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    img, label = self.subset[idx]\n",
    "    return self.transform(img), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25539653",
   "metadata": {
    "id": "ukRVwqmtpBLX",
    "papermill": {
     "duration": 0.002636,
     "end_time": "2025-03-08T07:52:35.841438",
     "exception": false,
     "start_time": "2025-03-08T07:52:35.838802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Train model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6caa64b",
   "metadata": {
    "id": "qNhNeRZl-6Kt",
    "papermill": {
     "duration": 0.002485,
     "end_time": "2025-03-08T07:52:35.846679",
     "exception": false,
     "start_time": "2025-03-08T07:52:35.844194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ResNet50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3dc0be7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T07:52:35.852666Z",
     "iopub.status.busy": "2025-03-08T07:52:35.852469Z",
     "iopub.status.idle": "2025-03-08T07:52:35.856714Z",
     "shell.execute_reply": "2025-03-08T07:52:35.855900Z"
    },
    "id": "jsGwyVnr-758",
    "papermill": {
     "duration": 0.00861,
     "end_time": "2025-03-08T07:52:35.857954",
     "exception": false,
     "start_time": "2025-03-08T07:52:35.849344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class FashionModel(nn.Module):\n",
    "  def __init__(self, num_classes):\n",
    "    super().__init__()\n",
    "    self.num_classes = num_classes\n",
    "    self.backbone = torchvision.models.resnet50(torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "    last_num_features = self.backbone.fc.in_features\n",
    "    self.backbone.fc = nn.Identity()\n",
    "    self.fc = nn.Linear(in_features=last_num_features, out_features=num_classes) # replace last fc layer\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.backbone(x)\n",
    "    return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7718c9",
   "metadata": {
    "id": "vWPOwBnR_Gze",
    "papermill": {
     "duration": 0.002902,
     "end_time": "2025-03-08T07:52:35.863751",
     "exception": false,
     "start_time": "2025-03-08T07:52:35.860849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02b35b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T07:52:35.870586Z",
     "iopub.status.busy": "2025-03-08T07:52:35.870394Z",
     "iopub.status.idle": "2025-03-08T07:52:35.875582Z",
     "shell.execute_reply": "2025-03-08T07:52:35.874923Z"
    },
    "id": "mp43pvr74iOb",
    "papermill": {
     "duration": 0.009914,
     "end_time": "2025-03-08T07:52:35.876695",
     "exception": false,
     "start_time": "2025-03-08T07:52:35.866781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import torch\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "import torch.multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from dataset_loading import FashionDataset, TransformedDataset\n",
    "from model import FashionModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def data_prepare():\n",
    "    # create dataset\n",
    "    ## data transformations\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    valtest_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    img_dir = '/kaggle/input/fashion/filtered_cropped_images'\n",
    "    dataset = FashionDataset(image_dir=img_dir)\n",
    "    train_set, val_set, test_set = random_split(\n",
    "        dataset,\n",
    "        lengths=[0.6, 0.2, 0.2],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    ## apply transformation\n",
    "    train_set = TransformedDataset(train_set, transform=train_transform)\n",
    "    val_set = TransformedDataset(val_set, transform=valtest_transform)\n",
    "    test_set = TransformedDataset(test_set, transform=valtest_transform)\n",
    "    \n",
    "    # create data loader\n",
    "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, dataset.num_classes\n",
    "\n",
    "# train loop\n",
    "def train_model(train_loader, val_loader, test_loader, model, optimizer, scheduler):        \n",
    "    accelerator = Accelerator()\n",
    "    train_loader, val_loader, model, optimizer, scheduler = accelerator.prepare(\n",
    "        train_loader, val_loader, model, optimizer, scheduler\n",
    "    )\n",
    "    \n",
    "    num_epochs = 100\n",
    "    best_acc = 0.0\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    train_losses = [] # save train losses for visualization\n",
    "    val_losses = [] # save validation loss for visualization\n",
    "    train_accuracies = [] # save train accuracy for visualization\n",
    "    val_accuracies = [] # save validation accuracy for visualization\n",
    "    for epoch in range(num_epochs):\n",
    "      model.train()\n",
    "      train_loss, correct, total = 0, 0, 0\n",
    "      loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "      for images, labels in loop:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # training phase\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "        all_gpu_loss = accelerator.gather(loss).mean().item()\n",
    "        train_loss += all_gpu_loss\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    \n",
    "        # update visualization\n",
    "        loop.set_postfix(loss=all_gpu_loss, acc=correct / total)\n",
    "    \n",
    "      scheduler.step()  \n",
    "      train_acc = correct / total\n",
    "      train_accuracies.append(train_acc)\n",
    "      train_losses.append(train_loss / len(train_loader))\n",
    "    \n",
    "      # evaluation phase\n",
    "      model.eval()\n",
    "      val_loss, correct, total = 0, 0, 0\n",
    "      with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          outputs = model(images)\n",
    "          loss = criterion(outputs, labels)\n",
    "          val_loss += loss.item()\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum()\n",
    "    \n",
    "      val_losses.append(val_loss / len(val_loader))\n",
    "      val_acc = correct / total\n",
    "      val_accuracies.append(val_acc)\n",
    "      print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "      # save checkpoint\n",
    "      if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        \n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        # Lưu lại state_dict\n",
    "        torch.save(unwrapped_model.state_dict(), \"/kaggle/working/best.pth\")\n",
    "        patience_counter = 0\n",
    "      else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "          print(f'Early stopping at epoch {epoch+1}.')\n",
    "          break\n",
    "    else:\n",
    "      print(f'Finished {num_epochs} epochs.')\n",
    "      unwrapped_model = accelerator.unwrap_model(model)\n",
    "      # Lưu lại state_dict\n",
    "      torch.save(unwrapped_model.state_dict(), \"/kaggle/working/last.pth\")\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "def visualize(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    # train/val loss visualize\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    sns.set_style(\"whitegrid\")  # Thêm nền grid nhẹ\n",
    "    \n",
    "    # Vẽ đường train loss\n",
    "    sns.lineplot(x=range(1, len(train_losses)+1), y=train_losses, marker='o', linestyle='-', color='red', label=\"Train Loss\")\n",
    "    \n",
    "    # Vẽ đường val loss\n",
    "    sns.lineplot(x=range(1, len(val_losses)+1), y=val_losses, marker='s', linestyle='--', color='blue', label=\"Validation Loss\")\n",
    "    \n",
    "    # Tùy chỉnh biểu đồ\n",
    "    plt.title(\"Train vs Validation Loss\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(\"Loss\", fontsize=12)\n",
    "    plt.xticks(range(1, 41))\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.savefig('/kaggle/working/train_val_losses.png')\n",
    "\n",
    "    \n",
    "    # train/val accuracies visualize\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    sns.set_style(\"whitegrid\")  # Thêm nền grid nhẹ\n",
    "    \n",
    "    # Vẽ đường train loss\n",
    "    sns.lineplot(x=range(1, len(train_accuracies)+1), y=train_accuracies, marker='o', linestyle='-', color='red', label=\"Train accuracy\")\n",
    "    \n",
    "    # Vẽ đường val loss\n",
    "    sns.lineplot(x=range(1, len(val_accuracies)+1), y=val_accuracies, marker='s', linestyle='--', color='blue', label=\"Validation accuracy\")\n",
    "    \n",
    "    # Tùy chỉnh biểu đồ\n",
    "    plt.title(\"Train vs Validation Accuracy\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "    plt.xticks(range(1, 41))\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.savefig('/kaggle/working/train_val_accuracies.png')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "    # prepare data loader\n",
    "    train_loader, val_loader, test_loader, num_classes = data_prepare()\n",
    "\n",
    "    # create model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = FashionModel(num_classes=num_classes).to(device)\n",
    "    \n",
    "    # loss function and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "    \n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = train_model(train_loader, val_loader, test_loader, model, optimizer, scheduler)\n",
    "    \n",
    "    visualize(train_losses, val_losses, train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e55c956e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T07:52:35.883343Z",
     "iopub.status.busy": "2025-03-08T07:52:35.883105Z",
     "iopub.status.idle": "2025-03-08T07:52:36.000624Z",
     "shell.execute_reply": "2025-03-08T07:52:35.999895Z"
    },
    "papermill": {
     "duration": 0.122383,
     "end_time": "2025-03-08T07:52:36.002041",
     "exception": false,
     "start_time": "2025-03-08T07:52:35.879658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_loading.py  model.py  __notebook__.ipynb  train.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae874e4",
   "metadata": {
    "papermill": {
     "duration": 0.002723,
     "end_time": "2025-03-08T07:52:36.008108",
     "exception": false,
     "start_time": "2025-03-08T07:52:36.005385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Run this to start train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b973b894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T07:52:36.014552Z",
     "iopub.status.busy": "2025-03-08T07:52:36.014318Z",
     "iopub.status.idle": "2025-03-08T08:40:31.859617Z",
     "shell.execute_reply": "2025-03-08T08:40:31.858553Z"
    },
    "papermill": {
     "duration": 2875.850462,
     "end_time": "2025-03-08T08:40:31.861352",
     "exception": false,
     "start_time": "2025-03-08T07:52:36.010890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\r\n",
      "  warnings.warn(\r\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\r\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\r\n",
      "100%|██████████████████████████████████████| 97.8M/97.8M [00:01<00:00, 88.3MB/s]\r\n",
      "100%|██████████████████████████████████████| 97.8M/97.8M [00:01<00:00, 86.4MB/s]\r\n",
      "Epoch 1/100: 100%|█| 206/206 [02:04<00:00,  1.65it/s, acc=tensor(0.5349, device=\r\n",
      "Epoch 1/100: 100%|█| 206/206 [02:04<00:00,  1.65it/s, acc=tensor(0.5616, device=\r\n",
      "Epoch 1: Train Acc: 0.53% | Val Acc: 0.67%\r\n",
      "Epoch 2/100:   0%|                                      | 0/206 [00:00<?, ?it/s]Epoch 1: Train Acc: 0.56% | Val Acc: 0.71%\r\n",
      "Epoch 2/100: 100%|█| 206/206 [01:39<00:00,  2.08it/s, acc=tensor(0.7676, device=\r\n",
      "Epoch 2/100: 100%|█| 206/206 [01:39<00:00,  2.07it/s, acc=tensor(0.7570, device=\r\n",
      "Epoch 2: Train Acc: 0.76% | Val Acc: 0.73%\r\n",
      "Epoch 3/100:   0%|                                      | 0/206 [00:00<?, ?it/s]Epoch 2: Train Acc: 0.77% | Val Acc: 0.75%\r\n",
      "Epoch 3/100: 100%|█| 206/206 [01:38<00:00,  2.10it/s, acc=tensor(0.8525, device=\r\n",
      "Epoch 3/100: 100%|█| 206/206 [01:38<00:00,  2.09it/s, acc=tensor(0.8509, device=\r\n",
      "Epoch 3: Train Acc: 0.85% | Val Acc: 0.75%\r\n",
      "Epoch 3: Train Acc: 0.85% | Val Acc: 0.77%\r\n",
      "Epoch 4/100: 100%|█| 206/206 [01:38<00:00,  2.09it/s, acc=tensor(0.9102, device=\r\n",
      "Epoch 4/100: 100%|█| 206/206 [01:38<00:00,  2.09it/s, acc=tensor(0.9067, device=\r\n",
      "Epoch 4: Train Acc: 0.91% | Val Acc: 0.75%\r\n",
      "Epoch 5/100:   0%|                                      | 0/206 [00:00<?, ?it/s]Epoch 4: Train Acc: 0.91% | Val Acc: 0.76%\r\n",
      "Epoch 5/100: 100%|█| 206/206 [01:37<00:00,  2.10it/s, acc=tensor(0.9455, device=\r\n",
      "Epoch 5/100: 100%|█| 206/206 [01:38<00:00,  2.10it/s, acc=tensor(0.9440, device=\r\n",
      "Epoch 5: Train Acc: 0.94% | Val Acc: 0.76%\r\n",
      "Epoch 6/100:   0%|                                      | 0/206 [00:00<?, ?it/s]Epoch 5: Train Acc: 0.95% | Val Acc: 0.78%\r\n",
      "Epoch 6/100: 100%|█| 206/206 [01:37<00:00,  2.11it/s, acc=tensor(0.9659, device=\r\n",
      "Epoch 6/100: 100%|█| 206/206 [01:37<00:00,  2.11it/s, acc=tensor(0.9633, device=\r\n",
      "Epoch 6: Train Acc: 0.96% | Val Acc: 0.76%\r\n",
      "Epoch 6: Train Acc: 0.97% | Val Acc: 0.78%\r\n",
      "Epoch 7/100: 100%|█| 206/206 [01:37<00:00,  2.12it/s, acc=tensor(0.9775, device=\r\n",
      "Epoch 7/100: 100%|█| 206/206 [01:37<00:00,  2.12it/s, acc=tensor(0.9792, device=\r\n",
      "Epoch 7: Train Acc: 0.98% | Val Acc: 0.78%\r\n",
      "Epoch 7: Train Acc: 0.98% | Val Acc: 0.79%\r\n",
      "Epoch 8/100: 100%|█| 206/206 [01:37<00:00,  2.12it/s, acc=tensor(0.9882, device=\r\n",
      "Epoch 8/100: 100%|█| 206/206 [01:37<00:00,  2.11it/s, acc=tensor(0.9853, device=\r\n",
      "Epoch 8: Train Acc: 0.99% | Val Acc: 0.78%\r\n",
      "Epoch 9/100:   0%|                                      | 0/206 [00:00<?, ?it/s]Epoch 8: Train Acc: 0.99% | Val Acc: 0.80%\r\n",
      "Epoch 9/100: 100%|█| 206/206 [01:37<00:00,  2.11it/s, acc=tensor(0.9901, device=\r\n",
      "Epoch 9/100: 100%|█| 206/206 [01:37<00:00,  2.12it/s, acc=tensor(0.9912, device=\r\n",
      "Epoch 9: Train Acc: 0.99% | Val Acc: 0.79%\r\n",
      "Epoch 10/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 9: Train Acc: 0.99% | Val Acc: 0.80%\r\n",
      "Epoch 10/100: 100%|█| 206/206 [01:38<00:00,  2.10it/s, acc=tensor(0.9936, device\r\n",
      "Epoch 10/100: 100%|█| 206/206 [01:37<00:00,  2.11it/s, acc=tensor(0.9932, device\r\n",
      "Epoch 10: Train Acc: 0.99% | Val Acc: 0.79%\r\n",
      "Epoch 11/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 10: Train Acc: 0.99% | Val Acc: 0.80%\r\n",
      "Epoch 11/100: 100%|█| 206/206 [01:38<00:00,  2.10it/s, acc=tensor(0.9947, device\r\n",
      "Epoch 11/100: 100%|█| 206/206 [01:38<00:00,  2.09it/s, acc=tensor(0.9939, device\r\n",
      "Epoch 11: Train Acc: 0.99% | Val Acc: 0.79%\r\n",
      "Epoch 12/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 11: Train Acc: 0.99% | Val Acc: 0.81%\r\n",
      "Epoch 12/100: 100%|█| 206/206 [01:38<00:00,  2.10it/s, acc=tensor(0.9959, device\r\n",
      "Epoch 12/100: 100%|█| 206/206 [01:37<00:00,  2.11it/s, acc=tensor(0.9930, device\r\n",
      "Epoch 12: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 13/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 12: Train Acc: 0.99% | Val Acc: 0.81%\r\n",
      "Epoch 13/100: 100%|█| 206/206 [01:37<00:00,  2.12it/s, acc=tensor(0.9968, device\r\n",
      "Epoch 13/100: 100%|█| 206/206 [01:36<00:00,  2.13it/s, acc=tensor(0.9961, device\r\n",
      "Epoch 13: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 14/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 13: Train Acc: 1.00% | Val Acc: 0.81%\r\n",
      "Epoch 14/100: 100%|█| 206/206 [01:37<00:00,  2.11it/s, acc=tensor(0.9962, device\r\n",
      "Epoch 14/100: 100%|█| 206/206 [01:37<00:00,  2.10it/s, acc=tensor(0.9970, device\r\n",
      "Epoch 14: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 15/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 14: Train Acc: 1.00% | Val Acc: 0.81%\r\n",
      "Epoch 15/100: 100%|█| 206/206 [01:38<00:00,  2.10it/s, acc=tensor(0.9956, device\r\n",
      "Epoch 15/100: 100%|█| 206/206 [01:38<00:00,  2.09it/s, acc=tensor(0.9971, device\r\n",
      "Epoch 15: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 15: Train Acc: 1.00% | Val Acc: 0.81%\r\n",
      "Epoch 16/100: 100%|█| 206/206 [01:38<00:00,  2.09it/s, acc=tensor(0.9970, device\r\n",
      "Epoch 16/100: 100%|█| 206/206 [01:38<00:00,  2.09it/s, acc=tensor(0.9979, device\r\n",
      "Epoch 16: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 17/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 16: Train Acc: 1.00% | Val Acc: 0.81%\r\n",
      "Epoch 17/100: 100%|█| 206/206 [01:37<00:00,  2.11it/s, acc=tensor(0.9977, device\r\n",
      "Epoch 17/100: 100%|█| 206/206 [01:37<00:00,  2.11it/s, acc=tensor(0.9974, device\r\n",
      "Epoch 17: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 18/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 17: Train Acc: 1.00% | Val Acc: 0.81%\r\n",
      "Epoch 18/100: 100%|█| 206/206 [01:37<00:00,  2.12it/s, acc=tensor(0.9976, device\r\n",
      "Epoch 18/100: 100%|█| 206/206 [01:37<00:00,  2.12it/s, acc=tensor(0.9979, device\r\n",
      "Epoch 18: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 19/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 18: Train Acc: 1.00% | Val Acc: 0.81%\r\n",
      "Epoch 19/100: 100%|█| 206/206 [01:37<00:00,  2.11it/s, acc=tensor(0.9980, device\r\n",
      "Epoch 19/100: 100%|█| 206/206 [01:37<00:00,  2.11it/s, acc=tensor(0.9973, device\r\n",
      "Epoch 19: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 20/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 19: Train Acc: 1.00% | Val Acc: 0.81%\r\n",
      "Epoch 20/100: 100%|█| 206/206 [01:37<00:00,  2.12it/s, acc=tensor(0.9965, device\r\n",
      "Epoch 20/100: 100%|█| 206/206 [01:37<00:00,  2.12it/s, acc=tensor(0.9974, device\r\n",
      "Epoch 20: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 21/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 20: Train Acc: 1.00% | Val Acc: 0.81%\r\n",
      "Epoch 21/100: 100%|█| 206/206 [01:37<00:00,  2.12it/s, acc=tensor(0.9983, device\r\n",
      "Epoch 21/100: 100%|█| 206/206 [01:37<00:00,  2.12it/s, acc=tensor(0.9971, device\r\n",
      "Epoch 21: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 22/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 21: Train Acc: 1.00% | Val Acc: 0.81%\r\n",
      "Epoch 22/100: 100%|█| 206/206 [01:37<00:00,  2.11it/s, acc=tensor(0.9973, device\r\n",
      "Epoch 22/100: 100%|█| 206/206 [01:37<00:00,  2.11it/s, acc=tensor(0.9977, device\r\n",
      "Epoch 22: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 23/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 22: Train Acc: 1.00% | Val Acc: 0.81%\r\n",
      "Epoch 23/100: 100%|█| 206/206 [01:38<00:00,  2.08it/s, acc=tensor(0.9983, device\r\n",
      "Epoch 23/100: 100%|█| 206/206 [01:39<00:00,  2.08it/s, acc=tensor(0.9980, device\r\n",
      "Epoch 23: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 24/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 23: Train Acc: 1.00% | Val Acc: 0.81%\r\n",
      "Epoch 24/100: 100%|█| 206/206 [01:39<00:00,  2.08it/s, acc=tensor(0.9971, device\r\n",
      "Epoch 24/100: 100%|█| 206/206 [01:39<00:00,  2.07it/s, acc=tensor(0.9983, device\r\n",
      "Epoch 24: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 24: Train Acc: 1.00% | Val Acc: 0.81%\r\n",
      "Epoch 25/100: 100%|█| 206/206 [01:37<00:00,  2.10it/s, acc=tensor(0.9980, device\r\n",
      "Epoch 25/100: 100%|█| 206/206 [01:37<00:00,  2.10it/s, acc=tensor(0.9974, device\r\n",
      "Epoch 25: Train Acc: 1.00% | Val Acc: 0.79%\r\n",
      "Epoch 26/100:   0%|                                     | 0/206 [00:00<?, ?it/s]Epoch 25: Train Acc: 1.00% | Val Acc: 0.81%\r\n",
      "Early stopping at epoch 25.\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "[rank0]: Traceback (most recent call last):\r\n",
      "[rank0]:   File \"/kaggle/working/train.py\", line 188, in <module>\r\n",
      "[rank0]:     visualize(train_losses, val_losses, train_accuracies, val_accuracies)\r\n",
      "[rank0]:   File \"/kaggle/working/train.py\", line 157, in visualize\r\n",
      "[rank0]:     sns.lineplot(x=range(1, len(train_accuracies)+1), y=train_accuracies, marker='o', linestyle='-', color='red', label=\"Train accuracy\")\r\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/seaborn/relational.py\", line 618, in lineplot\r\n",
      "[rank0]:     p = _LinePlotter(\r\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/seaborn/relational.py\", line 365, in __init__\r\n",
      "[rank0]:     super().__init__(data=data, variables=variables)\r\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py\", line 640, in __init__\r\n",
      "[rank0]:     self.assign_variables(data, variables)\r\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py\", line 701, in assign_variables\r\n",
      "[rank0]:     plot_data, variables = self._assign_variables_longform(\r\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py\", line 962, in _assign_variables_longform\r\n",
      "[rank0]:     plot_data = pd.DataFrame(plot_data)\r\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\", line 778, in __init__\r\n",
      "[rank0]:     mgr = dict_to_mgr(data, index, columns, dtype=dtype, copy=copy, typ=manager)\r\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\", line 503, in dict_to_mgr\r\n",
      "[rank0]:     return arrays_to_mgr(arrays, columns, index, dtype=dtype, typ=typ, consolidate=copy)\r\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\", line 119, in arrays_to_mgr\r\n",
      "[rank0]:     arrays, refs = _homogenize(arrays, index, dtype)\r\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\", line 629, in _homogenize\r\n",
      "[rank0]:     val = sanitize_array(val, index, dtype=dtype, copy=False)\r\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/pandas/core/construction.py\", line 654, in sanitize_array\r\n",
      "[rank0]:     subarr = maybe_convert_platform(data)\r\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py\", line 130, in maybe_convert_platform\r\n",
      "[rank0]:     arr = construct_1d_object_array_from_listlike(values)\r\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py\", line 1600, in construct_1d_object_array_from_listlike\r\n",
      "[rank0]:     result[:] = values\r\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 1151, in __array__\r\n",
      "[rank0]:     return self.numpy().astype(dtype, copy=False)\r\n",
      "[rank0]: TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\r\n",
      "[rank0]:[W308 08:40:29.594242310 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\r\n",
      "W0308 08:40:30.637000 32 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 42 closing signal SIGTERM\r\n",
      "/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\r\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\r\n",
      "E0308 08:40:30.901000 32 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 41) of binary: /usr/bin/python3\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1159, in launch_command\r\n",
      "    multi_gpu_launcher(args)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 793, in multi_gpu_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 910, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "train.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "  <NO_OTHER_FAILURES>\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2025-03-08_08:40:30\r\n",
      "  host      : 955d540218e6\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 41)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d686e9",
   "metadata": {
    "papermill": {
     "duration": 0.257685,
     "end_time": "2025-03-08T08:40:32.431233",
     "exception": false,
     "start_time": "2025-03-08T08:40:32.173548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56655c3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T08:40:32.941796Z",
     "iopub.status.busy": "2025-03-08T08:40:32.941294Z",
     "iopub.status.idle": "2025-03-08T08:41:19.838029Z",
     "shell.execute_reply": "2025-03-08T08:41:19.837133Z"
    },
    "papermill": {
     "duration": 47.422928,
     "end_time": "2025-03-08T08:41:20.107546",
     "exception": false,
     "start_time": "2025-03-08T08:40:32.684618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "<ipython-input-6-fd2338cb93ba>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load('/kaggle/working/best.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7807498574256897\n"
     ]
    }
   ],
   "source": [
    "from train import data_prepare\n",
    "from model import FashionModel\n",
    "import torch\n",
    "\n",
    "train_loader, val_loader, test_loader, num_classes = data_prepare()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FashionModel(num_classes)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(\n",
    "    torch.load('/kaggle/working/best.pth', map_location=device)\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct, total = 0, 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    print(f'Test accuracy: {correct / total}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2e5PXNwo65x7",
    "fM4wF-hn-vXt"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6816541,
     "sourceId": 10957199,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 260512,
     "modelInstanceId": 238850,
     "sourceId": 278850,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 260575,
     "modelInstanceId": 238912,
     "sourceId": 278915,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2928.352226,
   "end_time": "2025-03-08T08:41:21.589470",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-08T07:52:33.237244",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
