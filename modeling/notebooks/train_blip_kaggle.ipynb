{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb7411e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T00:26:54.108528Z",
     "iopub.status.busy": "2025-04-06T00:26:54.108146Z",
     "iopub.status.idle": "2025-04-06T00:27:06.387214Z",
     "shell.execute_reply": "2025-04-06T00:27:06.386000Z"
    },
    "papermill": {
     "duration": 12.28413,
     "end_time": "2025-04-06T00:27:06.389345",
     "exception": false,
     "start_time": "2025-04-06T00:26:54.105215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q pycocoevalcap\n",
    "!pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfed285b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-06T00:27:06.398000Z",
     "iopub.status.busy": "2025-04-06T00:27:06.397707Z",
     "iopub.status.idle": "2025-04-06T00:27:06.403760Z",
     "shell.execute_reply": "2025-04-06T00:27:06.402901Z"
    },
    "papermill": {
     "duration": 0.011906,
     "end_time": "2025-04-06T00:27:06.405224",
     "exception": false,
     "start_time": "2025-04-06T00:27:06.393318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_loading.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_loading.py\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "class HnMDataset(Dataset):\n",
    "    def __init__(self, dataset, processor):\n",
    "        self.dataset = dataset\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        encoding = self.processor(images=item[\"image\"], text=item[\"text\"], padding=\"max_length\", return_tensors=\"pt\")\n",
    "        # remove batch dimension\n",
    "        encoding = {k:v.squeeze() for k,v in encoding.items()}\n",
    "        return encoding\n",
    "\n",
    "def prepare_data(dataset, data_processor, train_size, batch_size):\n",
    "    # create dataset\n",
    "    ds = load_dataset(dataset, split='train')\n",
    "    dataset = HnMDataset(ds, data_processor)\n",
    "    \n",
    "    # train/val split\n",
    "    train_set, val_set = random_split(dataset, lengths=[0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    # data loader\n",
    "    train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_set, shuffle=False, batch_size=2 * batch_size)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdba5902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T00:27:06.412624Z",
     "iopub.status.busy": "2025-04-06T00:27:06.412403Z",
     "iopub.status.idle": "2025-04-06T00:27:06.416723Z",
     "shell.execute_reply": "2025-04-06T00:27:06.416027Z"
    },
    "papermill": {
     "duration": 0.009201,
     "end_time": "2025-04-06T00:27:06.417937",
     "exception": false,
     "start_time": "2025-04-06T00:27:06.408736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing metrics.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile metrics.py\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "\n",
    "def cider_score(ground_truth, generated):\n",
    "    cider_score, _ = Cider().compute_score({i: [gt] for i, gt in enumerate(ground_truth)},\n",
    "                                          {i: [pred] for i, pred in enumerate(generated)})\n",
    "    return cider_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "076b05ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T00:27:06.425569Z",
     "iopub.status.busy": "2025-04-06T00:27:06.425241Z",
     "iopub.status.idle": "2025-04-06T00:27:06.429229Z",
     "shell.execute_reply": "2025-04-06T00:27:06.428529Z"
    },
    "papermill": {
     "duration": 0.009043,
     "end_time": "2025-04-06T00:27:06.430454",
     "exception": false,
     "start_time": "2025-04-06T00:27:06.421411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "from transformers import AutoProcessor, BlipForConditionalGeneration\n",
    "\n",
    "def prepare_model(freeze_vit=False, freeze_bert=False):\n",
    "    # load model and processor\n",
    "    processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "    # freeze parameters of ViT\n",
    "    if freeze_vit:\n",
    "        for parameter in model._modules['vision_model'].parameters():\n",
    "            parameter.requires_grad = False\n",
    "\n",
    "    if freeze_bert:\n",
    "        for parameter in model._modules['text_decoder'].parameters():\n",
    "            parameter.requires_grad = False\n",
    "\n",
    "    return model, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9881862d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T00:27:06.438262Z",
     "iopub.status.busy": "2025-04-06T00:27:06.438061Z",
     "iopub.status.idle": "2025-04-06T00:27:06.443144Z",
     "shell.execute_reply": "2025-04-06T00:27:06.442342Z"
    },
    "papermill": {
     "duration": 0.010425,
     "end_time": "2025-04-06T00:27:06.444437",
     "exception": false,
     "start_time": "2025-04-06T00:27:06.434012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import torch\n",
    "from data_loading import prepare_data\n",
    "from model import prepare_model\n",
    "from tqdm import tqdm\n",
    "from accelerate import Accelerator\n",
    "from transformers import AdamW\n",
    "from transformers import get_scheduler\n",
    "import wandb\n",
    "from metrics import cider_score\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "import os\n",
    "        \n",
    "def save_checkpoint(save_path, model, epoch, best_cider, optimizer=None, lr_scheduler=None):\n",
    "    checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "            'best_metric': best_cider\n",
    "        }\n",
    "    torch.save(checkpoint, save_path)\n",
    "\n",
    "def train_blip(\n",
    "    num_epochs, batch_size, train_size, lr=5e-5, weight_decay=0.01,\n",
    "    caption_max_length=35,\n",
    "    freeze_vit=False, freeze_bert=False, \n",
    "    checkpoint_path=None, logger=None\n",
    "):\n",
    "    # metrics\n",
    "    best_cider = 0.0   # can be changed if load checkpoint\n",
    "\n",
    "    # prepare model\n",
    "    model, processor = prepare_model(freeze_vit=freeze_vit, freeze_bert=freeze_bert)\n",
    "    \n",
    "    # prepare data\n",
    "    train_loader, val_loader = prepare_data(\n",
    "        dataset='tomytjandra/h-and-m-fashion-caption', data_processor=processor,\n",
    "        train_size=train_size, batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # lr scheduler\n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"cosine\", optimizer=optimizer, num_warmup_steps=0.1 * num_training_steps, \n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "    \n",
    "    # continue from checkpoint if specify\n",
    "    if checkpoint_path is not None:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        best_cider = checkpoint['best_metric']\n",
    "        print(f\"Checkpoint loaded: Resuming from Epoch {epoch}, best_cider={best_cider}\")\n",
    "\n",
    "\n",
    "    # TRAINING LOOPS\n",
    "    \n",
    "    # accelerator to use dual gpu\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    accelerator = Accelerator()\n",
    "    train_loader, val_loader, model, optimizer, lr_scheduler = accelerator.prepare(\n",
    "            train_loader, val_loader, model, optimizer, lr_scheduler \n",
    "    )\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loops = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        epoch_loss = 0.0\n",
    "        for batch in train_loops:\n",
    "            input_ids = batch.pop(\"input_ids\").to(device)\n",
    "            pixel_values = batch.pop(\"pixel_values\").to(device)\n",
    "    \n",
    "            outputs = model(input_ids=input_ids,\n",
    "                            pixel_values=pixel_values,\n",
    "                            labels=input_ids)\n",
    "    \n",
    "            loss = outputs.loss\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # update scheduler\n",
    "            lr_scheduler.step()\n",
    "    \n",
    "            # visualize batch loss\n",
    "            all_gpu_loss = accelerator.gather(loss).mean().item()\n",
    "            epoch_loss += all_gpu_loss\n",
    "        epoch_loss /= len(train_loader)\n",
    "    \n",
    "        # evaluate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            ## val set                                                                          \n",
    "            eval_loops = tqdm(val_loader, desc=f'Validating epoch {epoch+1}/{num_epochs}:')\n",
    "            val_loss = 0.0\n",
    "            ground_truth = []\n",
    "            generated = []\n",
    "            for batch in eval_loops:\n",
    "                input_ids = batch.pop(\"input_ids\").to(device)\n",
    "                pixel_values = batch.pop(\"pixel_values\").to(device)\n",
    "    \n",
    "                outputs = model(input_ids=input_ids,\n",
    "                            pixel_values=pixel_values,\n",
    "                            labels=input_ids)\n",
    "                \n",
    "                # ground truth\n",
    "                gt_captions = processor.batch_decode(input_ids, skip_special_tokens=True)\n",
    "                ground_truth.extend(gt_captions)\n",
    "                # generated\n",
    "                generated_ids = model.module.generate(pixel_values=pixel_values, max_length=caption_max_length)\n",
    "                generated_captions = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "                generated.extend(generated_captions)\n",
    "            \n",
    "                # loss\n",
    "                loss = outputs.loss\n",
    "                all_gpu_loss = accelerator.gather(loss).mean().item()\n",
    "                val_loss += all_gpu_loss\n",
    "            val_loss /= len(val_loader)\n",
    "            val_cider = cider_score(ground_truth, generated)\n",
    "        \n",
    "            # log\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}: train_loss={epoch_loss:.6f}, val_loss={val_loss:.6f}, val_cider={val_cider:.6f}')\n",
    "            logger.log({'train_loss': epoch_loss, 'val_loss': val_loss, 'val_cider': val_cider})\n",
    "    \n",
    "            # save check point\n",
    "            if val_cider > best_cider:\n",
    "                unwrapped_model = accelerator.unwrap_model(model)\n",
    "                best_cider = val_cider\n",
    "                save_checkpoint('/kaggle/working/best.pth', unwrapped_model,\n",
    "                                   epoch+1, best_cider, optimizer, lr_scheduler)\n",
    "                print(f\"Best checkpoint saved at epoch {epoch+1}\")\n",
    "    \n",
    "    else:\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        save_checkpoint('/kaggle/working/last.pth', unwrapped_model, \n",
    "                            epoch+1, best_cider, optimizer, lr_scheduler)\n",
    "        print(f\"Last checkpoint saved.\")\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # login to wandb\n",
    "    os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"wandb api key\")\n",
    "    wandb.login(anonymous='never', key=api_key)\n",
    "    \n",
    "    # uncomment next line to resume from checkpoint\n",
    "    checkpoint_path='/kaggle/input/blip_8_epochs/pytorch/default/1/best.pth'\n",
    "\n",
    "    # initialize hyper-parameters\n",
    "    num_epochs = 9\n",
    "    lr = 5e-5\n",
    "    weight_decay = 0.01\n",
    "    caption_max_length = 50\n",
    "    freeze_vit = False\n",
    "    freeze_bert = False\n",
    "    \n",
    "    run = wandb.init(\n",
    "        id='unfreeze_vit',\n",
    "        project=\"train_blip_on_h&m\",\n",
    "        config={\n",
    "            \"dataset\": \"H&M captions\",\n",
    "            \"epochs\": num_epochs,\n",
    "            \"learning_rate\": lr,\n",
    "            'weight_decay': weight_decay,\n",
    "            'caption_max_length': caption_max_length,\n",
    "            'freeze_vit': freeze_vit,\n",
    "            'freeze_bert': freeze_bert,\n",
    "            'continue_from_checkpoint': checkpoint_path,\n",
    "            'machine': 'offline cluster'\n",
    "        },\n",
    "        resume='allow'\n",
    "    )\n",
    "    train_blip(num_epochs=num_epochs, batch_size=4, train_size=0.8, lr=lr, weight_decay=weight_decay,\n",
    "                caption_max_length=caption_max_length,\n",
    "                freeze_vit=freeze_vit, freeze_bert=freeze_bert, \n",
    "                checkpoint_path=checkpoint_path, logger=run\n",
    "    )\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d6555ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T00:27:06.452228Z",
     "iopub.status.busy": "2025-04-06T00:27:06.452018Z",
     "iopub.status.idle": "2025-04-06T11:24:59.036725Z",
     "shell.execute_reply": "2025-04-06T11:24:59.035554Z"
    },
    "papermill": {
     "duration": 39472.59037,
     "end_time": "2025-04-06T11:24:59.038381",
     "exception": false,
     "start_time": "2025-04-06T00:27:06.448011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-06 00:27:36.762761: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-04-06 00:27:36.762792: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-04-06 00:27:37.243115: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-04-06 00:27:37.243132: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-04-06 00:27:37.374611: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "2025-04-06 00:27:37.374616: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id unfreeze_vit.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id unfreeze_vit.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\r\n",
      "preprocessor_config.json: 100%|█████████████████| 287/287 [00:00<00:00, 921kB/s]\r\n",
      "tokenizer_config.json: 100%|███████████████████| 506/506 [00:00<00:00, 1.85MB/s]\r\n",
      "vocab.txt: 100%|█████████████████████████████| 232k/232k [00:00<00:00, 7.27MB/s]\r\n",
      "tokenizer.json: 100%|████████████████████████| 711k/711k [00:00<00:00, 29.6MB/s]\r\n",
      "special_tokens_map.json: 100%|██████████████████| 125/125 [00:00<00:00, 341kB/s]\r\n",
      "config.json: 100%|█████████████████████████| 4.56k/4.56k [00:00<00:00, 11.1MB/s]\r\n",
      "pytorch_model.bin: 100%|██████████████████████| 990M/990M [00:04<00:00, 238MB/s]\r\n",
      "README.md: 100%|███████████████████████████████| 502/502 [00:00<00:00, 1.22MB/s]\r\n",
      "Downloading data:   0%|                               | 0/16 [00:00<?, ?files/s]\r\n",
      "train-00000-of-00016.parquet:   0%|                  | 0.00/498M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:   2%|▏        | 10.5M/498M [00:00<00:06, 70.6MB/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:   6%|▋         | 31.5M/498M [00:00<00:03, 118MB/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:  11%|█         | 52.4M/498M [00:00<00:03, 141MB/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:  17%|█▋        | 83.9M/498M [00:00<00:02, 181MB/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:  23%|██▌        | 115M/498M [00:00<00:01, 207MB/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:  29%|███▏       | 147M/498M [00:00<00:01, 220MB/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:  36%|███▉       | 178M/498M [00:00<00:01, 228MB/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:  42%|████▋      | 210M/498M [00:01<00:01, 229MB/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:  48%|█████▎     | 241M/498M [00:01<00:01, 230MB/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:  55%|██████     | 273M/498M [00:01<00:00, 229MB/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:  61%|██████▋    | 304M/498M [00:01<00:00, 226MB/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:  67%|███████▍   | 336M/498M [00:01<00:00, 228MB/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:  74%|████████   | 367M/498M [00:01<00:00, 229MB/s]\u001b[A\r\n",
      "train-00000-of-00016.parquet:  80%|████████▊  | 398M/498M [00:01<00:00, 235MB/s]\u001b[A\r\n",
      "model.safetensors:   0%|                             | 0.00/990M [00:00<?, ?B/s]\r\n",
      "model.safetensors:   1%|▏                   | 10.5M/990M [00:00<00:09, 98.4MB/s]\r\n",
      "train-00000-of-00016.parquet: 100%|███████████| 498M/498M [00:02<00:00, 218MB/s]\r\n",
      "Downloading data:   6%|█▍                     | 1/16 [00:02<00:40,  2.67s/files]\r\n",
      "model.safetensors:   6%|█▎                   | 62.9M/990M [00:00<00:04, 200MB/s]\r\n",
      "model.safetensors:  10%|██                   | 94.4M/990M [00:00<00:04, 216MB/s]\r\n",
      "model.safetensors:  16%|███▍                  | 157M/990M [00:00<00:03, 224MB/s]\r\n",
      "model.safetensors:  19%|████▏                 | 189M/990M [00:00<00:03, 229MB/s]\r\n",
      "model.safetensors:  22%|████▉                 | 220M/990M [00:01<00:03, 229MB/s]\r\n",
      "model.safetensors:  25%|█████▌                | 252M/990M [00:01<00:03, 231MB/s]\r\n",
      "model.safetensors:  29%|██████▎               | 283M/990M [00:01<00:03, 230MB/s]\r\n",
      "model.safetensors:  32%|██████▉               | 315M/990M [00:01<00:02, 227MB/s]\r\n",
      "model.safetensors:  35%|███████▋              | 346M/990M [00:01<00:02, 230MB/s]\r\n",
      "model.safetensors:  38%|████████▍             | 377M/990M [00:01<00:02, 230MB/s]\r\n",
      "model.safetensors:  41%|█████████             | 409M/990M [00:01<00:02, 232MB/s]\r\n",
      "model.safetensors:  44%|█████████▊            | 440M/990M [00:01<00:02, 230MB/s]\r\n",
      "model.safetensors:  48%|██████████▍           | 472M/990M [00:02<00:02, 230MB/s]\r\n",
      "model.safetensors:  51%|███████████▏          | 503M/990M [00:02<00:02, 231MB/s]\r\n",
      "model.safetensors:  54%|███████████▉          | 535M/990M [00:02<00:01, 231MB/s]\r\n",
      "model.safetensors:  57%|████████████▌         | 566M/990M [00:02<00:01, 236MB/s]\r\n",
      "model.safetensors:  60%|█████████████▎        | 598M/990M [00:02<00:01, 235MB/s]\r\n",
      "train-00001-of-00016.parquet: 100%|███████████| 540M/540M [00:02<00:00, 218MB/s]\r\n",
      "model.safetensors:  67%|██████████████▋       | 661M/990M [00:02<00:01, 232MB/s]\r\n",
      "model.safetensors:  70%|███████████████▍      | 692M/990M [00:03<00:01, 230MB/s]\r\n",
      "model.safetensors:  73%|████████████████      | 724M/990M [00:03<00:01, 230MB/s]\r\n",
      "model.safetensors:  76%|████████████████▊     | 755M/990M [00:03<00:01, 230MB/s]\r\n",
      "model.safetensors:  79%|█████████████████▍    | 786M/990M [00:03<00:00, 228MB/s]\r\n",
      "model.safetensors:  83%|██████████████████▏   | 818M/990M [00:03<00:00, 229MB/s]\r\n",
      "model.safetensors:  86%|██████████████████▉   | 849M/990M [00:03<00:00, 229MB/s]\r\n",
      "model.safetensors:  89%|███████████████████▌  | 881M/990M [00:03<00:00, 231MB/s]\r\n",
      "model.safetensors:  92%|████████████████████▎ | 912M/990M [00:04<00:00, 225MB/s]\r\n",
      "model.safetensors:  95%|████████████████████▉ | 944M/990M [00:04<00:00, 222MB/s]\r\n",
      "model.safetensors:  99%|█████████████████████▋| 975M/990M [00:04<00:00, 222MB/s]\r\n",
      "model.safetensors: 100%|██████████████████████| 990M/990M [00:04<00:00, 225MB/s]\r\n",
      "\r\n",
      "train-00002-of-00016.parquet:  56%|██████▏    | 283M/506M [00:01<00:01, 211MB/s]\u001b[A\r\n",
      "train-00002-of-00016.parquet:  62%|██████▊    | 315M/506M [00:01<00:00, 214MB/s]\u001b[A\r\n",
      "train-00002-of-00016.parquet:  68%|███████▌   | 346M/506M [00:01<00:00, 219MB/s]\u001b[A\r\n",
      "train-00002-of-00016.parquet:  75%|████████▏  | 377M/506M [00:01<00:00, 217MB/s]\u001b[A\r\n",
      "train-00002-of-00016.parquet:  81%|████████▉  | 409M/506M [00:02<00:00, 219MB/s]\u001b[A\r\n",
      "train-00002-of-00016.parquet:  87%|█████████▌ | 440M/506M [00:02<00:00, 213MB/s]\u001b[A\r\n",
      "train-00002-of-00016.parquet:  93%|██████████▎| 472M/506M [00:02<00:00, 223MB/s]\u001b[A\r\n",
      "train-00002-of-00016.parquet: 100%|███████████| 506M/506M [00:02<00:00, 199MB/s]\r\n",
      "Downloading data:  19%|████▎                  | 3/16 [00:07<00:34,  2.64s/files]\r\n",
      "train-00003-of-00016.parquet:   0%|                  | 0.00/478M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:   2%|▏        | 10.5M/478M [00:00<00:05, 84.6MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:   7%|▋         | 31.5M/478M [00:00<00:04, 102MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  11%|█         | 52.4M/478M [00:00<00:03, 115MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  15%|█▌        | 73.4M/478M [00:00<00:03, 125MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  20%|█▉        | 94.4M/478M [00:00<00:02, 132MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  24%|██▋        | 115M/478M [00:00<00:02, 138MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  29%|███▏       | 136M/478M [00:01<00:02, 141MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  33%|███▌       | 157M/478M [00:01<00:02, 143MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  37%|████       | 178M/478M [00:01<00:02, 141MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  42%|████▌      | 199M/478M [00:01<00:01, 140MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  46%|█████      | 220M/478M [00:01<00:01, 141MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  50%|█████▌     | 241M/478M [00:01<00:01, 140MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  55%|██████     | 262M/478M [00:01<00:01, 140MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  59%|██████▌    | 283M/478M [00:02<00:01, 140MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  64%|██████▉    | 304M/478M [00:02<00:01, 140MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  68%|███████▍   | 325M/478M [00:02<00:01, 140MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  72%|███████▉   | 346M/478M [00:02<00:00, 142MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  77%|████████▍  | 367M/478M [00:02<00:00, 142MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  81%|████████  | 388M/478M [00:03<00:00, 97.6MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  86%|█████████▍ | 409M/478M [00:03<00:00, 108MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  90%|█████████▉ | 430M/478M [00:03<00:00, 117MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet:  94%|██████████▍| 451M/478M [00:03<00:00, 125MB/s]\u001b[A\r\n",
      "train-00003-of-00016.parquet: 100%|███████████| 478M/478M [00:03<00:00, 130MB/s]\r\n",
      "Downloading data:  25%|█████▊                 | 4/16 [00:11<00:37,  3.10s/files]\r\n",
      "train-00004-of-00016.parquet:   0%|                  | 0.00/386M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:   5%|▌         | 21.0M/386M [00:00<00:02, 122MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  11%|█         | 41.9M/386M [00:00<00:02, 135MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  16%|█▋        | 62.9M/386M [00:00<00:02, 139MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  22%|██▏       | 83.9M/386M [00:00<00:02, 141MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  27%|██▉        | 105M/386M [00:00<00:02, 139MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  33%|███▌       | 126M/386M [00:00<00:01, 142MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  38%|████▏      | 147M/386M [00:01<00:01, 144MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  43%|████▊      | 168M/386M [00:01<00:01, 140MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  49%|█████▍     | 189M/386M [00:01<00:01, 141MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  54%|█████▉     | 210M/386M [00:01<00:01, 143MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  60%|██████▌    | 231M/386M [00:01<00:01, 143MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  65%|███████▏   | 252M/386M [00:01<00:00, 144MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  71%|███████▊   | 273M/386M [00:01<00:00, 142MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  76%|████████▎  | 294M/386M [00:02<00:00, 143MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  82%|████████▉  | 315M/386M [00:02<00:00, 145MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  87%|█████████▌ | 336M/386M [00:02<00:00, 147MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet:  92%|██████████▏| 357M/386M [00:02<00:00, 144MB/s]\u001b[A\r\n",
      "train-00004-of-00016.parquet: 100%|███████████| 386M/386M [00:02<00:00, 142MB/s]\r\n",
      "Downloading data:  31%|███████▏               | 5/16 [00:14<00:32,  3.00s/files]\r\n",
      "train-00005-of-00016.parquet:   0%|                  | 0.00/379M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:   3%|▏        | 10.5M/379M [00:00<00:05, 72.1MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:   6%|▍        | 21.0M/379M [00:00<00:04, 73.1MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:   8%|▋        | 31.5M/379M [00:00<00:04, 82.1MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  14%|█▍        | 52.4M/379M [00:00<00:03, 100MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  19%|█▉        | 73.4M/379M [00:00<00:02, 114MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  25%|██▍       | 94.4M/379M [00:00<00:02, 121MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  30%|███▎       | 115M/379M [00:01<00:02, 126MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  36%|███▉       | 136M/379M [00:01<00:01, 131MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  42%|████▌      | 157M/379M [00:01<00:01, 134MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  47%|█████▏     | 178M/379M [00:01<00:01, 136MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  53%|█████▊     | 199M/379M [00:01<00:01, 139MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  58%|██████▍    | 220M/379M [00:01<00:01, 140MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  64%|███████    | 241M/379M [00:01<00:00, 139MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  69%|███████▌   | 262M/379M [00:02<00:00, 142MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  75%|████████▏  | 283M/379M [00:02<00:00, 143MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  80%|████████▊  | 304M/379M [00:02<00:00, 143MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  86%|█████████▍ | 325M/379M [00:02<00:00, 142MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet:  91%|██████████ | 346M/379M [00:02<00:00, 145MB/s]\u001b[A\r\n",
      "train-00005-of-00016.parquet: 100%|███████████| 379M/379M [00:02<00:00, 131MB/s]\r\n",
      "Downloading data:  38%|████████▋              | 6/16 [00:17<00:29,  2.99s/files]\r\n",
      "train-00006-of-00016.parquet:   0%|                  | 0.00/372M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:   6%|▌         | 21.0M/372M [00:00<00:02, 119MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  11%|█▏        | 41.9M/372M [00:00<00:02, 132MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  17%|█▋        | 62.9M/372M [00:00<00:02, 136MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  23%|██▎       | 83.9M/372M [00:00<00:02, 138MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  28%|███        | 105M/372M [00:00<00:01, 140MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  34%|███▋       | 126M/372M [00:00<00:01, 140MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  39%|████▎      | 147M/372M [00:01<00:01, 141MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  45%|████▉      | 168M/372M [00:01<00:01, 143MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  51%|█████▌     | 189M/372M [00:01<00:01, 145MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  56%|██████▏    | 210M/372M [00:01<00:01, 145MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  62%|██████▊    | 231M/372M [00:01<00:00, 146MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  68%|███████▍   | 252M/372M [00:01<00:00, 145MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  73%|████████   | 273M/372M [00:01<00:00, 145MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  79%|████████▋  | 294M/372M [00:02<00:00, 145MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  85%|█████████▎ | 315M/372M [00:02<00:00, 145MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  90%|█████████▉ | 336M/372M [00:02<00:00, 144MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet:  96%|██████████▌| 357M/372M [00:02<00:00, 144MB/s]\u001b[A\r\n",
      "train-00006-of-00016.parquet: 100%|███████████| 372M/372M [00:02<00:00, 141MB/s]\r\n",
      "Downloading data:  44%|██████████             | 7/16 [00:20<00:26,  2.91s/files]\r\n",
      "train-00007-of-00016.parquet:   0%|                  | 0.00/357M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:   6%|▌        | 21.0M/357M [00:00<00:03, 95.0MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:   9%|▊        | 31.5M/357M [00:00<00:03, 97.7MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  15%|█▍        | 52.4M/357M [00:00<00:02, 113MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  21%|██        | 73.4M/357M [00:00<00:02, 126MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  26%|██▋       | 94.4M/357M [00:00<00:02, 130MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  32%|███▌       | 115M/357M [00:00<00:01, 136MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  38%|████▏      | 136M/357M [00:01<00:01, 139MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  44%|████▊      | 157M/357M [00:01<00:01, 140MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  50%|█████▍     | 178M/357M [00:01<00:01, 142MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  56%|██████▏    | 199M/357M [00:01<00:01, 142MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  62%|██████▊    | 220M/357M [00:01<00:00, 143MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  68%|███████▍   | 241M/357M [00:01<00:00, 140MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  73%|████████   | 262M/357M [00:01<00:00, 132MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  79%|████████▋  | 283M/357M [00:02<00:00, 137MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  85%|█████████▎ | 304M/357M [00:02<00:00, 141MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet:  91%|██████████ | 325M/357M [00:02<00:00, 143MB/s]\u001b[A\r\n",
      "train-00007-of-00016.parquet: 100%|███████████| 357M/357M [00:02<00:00, 136MB/s]\r\n",
      "Downloading data:  50%|███████████▌           | 8/16 [00:22<00:22,  2.85s/files]\r\n",
      "train-00008-of-00016.parquet:   0%|                  | 0.00/359M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:   3%|▎        | 10.5M/359M [00:00<00:12, 28.5MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:   9%|▊        | 31.5M/359M [00:00<00:04, 68.7MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  15%|█▎       | 52.4M/359M [00:00<00:03, 94.9MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  20%|██        | 73.4M/359M [00:00<00:02, 112MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  26%|██▋       | 94.4M/359M [00:00<00:02, 124MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  32%|███▌       | 115M/359M [00:01<00:01, 131MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  38%|████▏      | 136M/359M [00:01<00:01, 136MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  44%|████▊      | 157M/359M [00:01<00:01, 140MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  50%|█████▍     | 178M/359M [00:01<00:01, 142MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  55%|██████     | 199M/359M [00:01<00:01, 141MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  61%|██████▋    | 220M/359M [00:01<00:00, 143MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  67%|███████▍   | 241M/359M [00:01<00:00, 144MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  73%|████████   | 262M/359M [00:02<00:00, 145MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  79%|████████▋  | 283M/359M [00:02<00:00, 146MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  85%|█████████▎ | 304M/359M [00:02<00:00, 144MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet:  90%|█████████▉ | 325M/359M [00:02<00:00, 144MB/s]\u001b[A\r\n",
      "train-00008-of-00016.parquet: 100%|███████████| 359M/359M [00:02<00:00, 129MB/s]\r\n",
      "Downloading data:  56%|████████████▉          | 9/16 [00:25<00:19,  2.86s/files]\r\n",
      "train-00009-of-00016.parquet:   0%|                  | 0.00/338M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:   3%|▎        | 10.5M/338M [00:00<00:04, 67.4MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:   6%|▌        | 21.0M/338M [00:00<00:04, 73.0MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:   9%|▊        | 31.5M/338M [00:00<00:03, 84.4MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:  16%|█▌        | 52.4M/338M [00:00<00:02, 109MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:  22%|██▏       | 73.4M/338M [00:00<00:02, 122MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:  28%|██▊       | 94.4M/338M [00:00<00:01, 131MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:  34%|███▊       | 115M/338M [00:00<00:01, 137MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:  40%|████▍      | 136M/338M [00:01<00:01, 142MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:  47%|█████▏     | 157M/338M [00:01<00:01, 144MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:  53%|█████▊     | 178M/338M [00:01<00:01, 144MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:  59%|██████▍    | 199M/338M [00:01<00:00, 144MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:  65%|███████▏   | 220M/338M [00:01<00:00, 144MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:  71%|███████▊   | 241M/338M [00:01<00:00, 143MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:  78%|████████▌  | 262M/338M [00:01<00:00, 143MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:  84%|█████████▏ | 283M/338M [00:02<00:00, 143MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet:  90%|█████████▉ | 304M/338M [00:02<00:00, 144MB/s]\u001b[A\r\n",
      "train-00009-of-00016.parquet: 100%|███████████| 338M/338M [00:02<00:00, 135MB/s]\r\n",
      "Downloading data:  62%|█████████████▊        | 10/16 [00:28<00:16,  2.78s/files]\r\n",
      "train-00010-of-00016.parquet:   0%|                  | 0.00/346M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:   3%|▎         | 10.5M/346M [00:00<00:03, 101MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:   9%|▉         | 31.5M/346M [00:00<00:02, 125MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  15%|█▌        | 52.4M/346M [00:00<00:02, 136MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  21%|██        | 73.4M/346M [00:00<00:01, 139MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  27%|██▋       | 94.4M/346M [00:00<00:01, 142MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  33%|███▋       | 115M/346M [00:00<00:01, 143MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  39%|████▎      | 136M/346M [00:00<00:01, 144MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  45%|████▉      | 157M/346M [00:01<00:01, 144MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  51%|█████▋     | 178M/346M [00:01<00:01, 144MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  58%|██████▎    | 199M/346M [00:01<00:01, 145MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  64%|██████▉    | 220M/346M [00:01<00:00, 146MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  70%|███████▋   | 241M/346M [00:01<00:00, 145MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  76%|████████▎  | 262M/346M [00:01<00:00, 146MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  82%|████████▉  | 283M/346M [00:01<00:00, 146MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  88%|█████████▋ | 304M/346M [00:02<00:00, 146MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet:  94%|██████████▎| 325M/346M [00:02<00:00, 147MB/s]\u001b[A\r\n",
      "train-00010-of-00016.parquet: 100%|███████████| 346M/346M [00:02<00:00, 143MB/s]\r\n",
      "Downloading data:  69%|███████████████▏      | 11/16 [00:30<00:13,  2.70s/files]\r\n",
      "train-00011-of-00016.parquet:   0%|                  | 0.00/360M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:   3%|▎        | 10.5M/360M [00:00<00:04, 78.6MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:   6%|▌        | 21.0M/360M [00:00<00:04, 77.7MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:   9%|▊        | 31.5M/360M [00:00<00:03, 85.3MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  15%|█▍        | 52.4M/360M [00:00<00:02, 105MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  20%|██        | 73.4M/360M [00:00<00:02, 119MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  26%|██▌       | 94.4M/360M [00:00<00:02, 126MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  32%|███▌       | 115M/360M [00:00<00:01, 133MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  38%|████▏      | 136M/360M [00:01<00:01, 135MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  44%|████▊      | 157M/360M [00:01<00:01, 136MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  50%|█████▍     | 178M/360M [00:01<00:01, 138MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  55%|██████     | 199M/360M [00:01<00:01, 138MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  61%|██████▋    | 220M/360M [00:01<00:00, 141MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  67%|███████▍   | 241M/360M [00:01<00:00, 143MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  73%|████████   | 262M/360M [00:02<00:00, 145MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  79%|████████▋  | 283M/360M [00:02<00:00, 145MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  85%|█████████▎ | 304M/360M [00:02<00:00, 146MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet:  90%|█████████▉ | 325M/360M [00:02<00:00, 147MB/s]\u001b[A\r\n",
      "train-00011-of-00016.parquet: 100%|███████████| 360M/360M [00:02<00:00, 134MB/s]\r\n",
      "Downloading data:  75%|████████████████▌     | 12/16 [00:33<00:10,  2.72s/files]\r\n",
      "train-00012-of-00016.parquet:   0%|                  | 0.00/357M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:   6%|▌         | 21.0M/357M [00:00<00:02, 124MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  12%|█▏        | 41.9M/357M [00:00<00:02, 136MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  18%|█▊        | 62.9M/357M [00:00<00:02, 141MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  24%|██▎       | 83.9M/357M [00:00<00:01, 142MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  29%|███▏       | 105M/357M [00:00<00:01, 143MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  35%|███▌      | 126M/357M [00:01<00:02, 96.2MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  41%|████▌      | 147M/357M [00:01<00:01, 109MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  47%|█████▏     | 168M/357M [00:01<00:01, 118MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  53%|█████▊     | 189M/357M [00:01<00:01, 125MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  59%|██████▍    | 210M/357M [00:01<00:01, 131MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  65%|███████    | 231M/357M [00:01<00:00, 137MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  71%|███████▊   | 252M/357M [00:01<00:00, 139MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  76%|████████▍  | 273M/357M [00:02<00:00, 142MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  82%|█████████  | 294M/357M [00:02<00:00, 144MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  88%|█████████▋ | 315M/357M [00:02<00:00, 146MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet:  94%|██████████▎| 336M/357M [00:02<00:00, 115MB/s]\u001b[A\r\n",
      "train-00012-of-00016.parquet: 100%|███████████| 357M/357M [00:02<00:00, 127MB/s]\r\n",
      "Downloading data:  81%|█████████████████▉    | 13/16 [00:36<00:08,  2.80s/files]\r\n",
      "train-00013-of-00016.parquet:   0%|                  | 0.00/341M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:   3%|▎        | 10.5M/341M [00:00<00:05, 57.4MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:   6%|▌        | 21.0M/341M [00:00<00:04, 74.7MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  12%|█▏        | 41.9M/341M [00:00<00:02, 103MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  18%|█▊        | 62.9M/341M [00:00<00:02, 118MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  25%|██▍       | 83.9M/341M [00:00<00:02, 127MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  31%|███▍       | 105M/341M [00:00<00:01, 132MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  37%|████       | 126M/341M [00:01<00:01, 136MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  43%|████▋      | 147M/341M [00:01<00:01, 139MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  49%|█████▍     | 168M/341M [00:01<00:01, 141MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  55%|██████     | 189M/341M [00:01<00:01, 142MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  61%|██████▊    | 210M/341M [00:01<00:00, 144MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  68%|███████▍   | 231M/341M [00:01<00:00, 146MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  74%|████████   | 252M/341M [00:01<00:00, 146MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  80%|████████▊  | 273M/341M [00:02<00:00, 147MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  86%|█████████▍ | 294M/341M [00:02<00:00, 146MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet:  92%|██████████▏| 315M/341M [00:02<00:00, 142MB/s]\u001b[A\r\n",
      "train-00013-of-00016.parquet: 100%|███████████| 341M/341M [00:02<00:00, 134MB/s]\r\n",
      "Downloading data:  88%|███████████████████▎  | 14/16 [00:39<00:05,  2.75s/files]\r\n",
      "train-00014-of-00016.parquet:   0%|                  | 0.00/338M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:   3%|▎        | 10.5M/338M [00:00<00:04, 75.7MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:   9%|▉         | 31.5M/338M [00:00<00:02, 112MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:  15%|█▌        | 52.4M/338M [00:00<00:02, 129MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:  22%|██▏       | 73.4M/338M [00:00<00:01, 137MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:  28%|██▊       | 94.4M/338M [00:00<00:01, 142MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:  34%|███▊       | 115M/338M [00:00<00:01, 144MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:  40%|████▍      | 136M/338M [00:00<00:01, 146MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:  46%|█████      | 157M/338M [00:01<00:01, 146MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:  53%|█████▊     | 178M/338M [00:01<00:01, 147MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:  59%|██████▍    | 199M/338M [00:01<00:00, 145MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:  65%|███████▏   | 220M/338M [00:01<00:00, 145MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:  71%|███████▊   | 241M/338M [00:01<00:00, 144MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:  77%|████████▌  | 262M/338M [00:01<00:00, 145MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:  84%|█████████▏ | 283M/338M [00:02<00:00, 144MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet:  90%|█████████▉ | 304M/338M [00:02<00:00, 143MB/s]\u001b[A\r\n",
      "train-00014-of-00016.parquet: 100%|███████████| 338M/338M [00:02<00:00, 141MB/s]\r\n",
      "Downloading data:  94%|████████████████████▋ | 15/16 [00:41<00:02,  2.67s/files]\r\n",
      "train-00015-of-00016.parquet:   0%|                  | 0.00/347M [00:00<?, ?B/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:   3%|▎        | 10.5M/347M [00:00<00:05, 60.4MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:   9%|▊        | 31.5M/347M [00:00<00:03, 82.1MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  15%|█▌        | 52.4M/347M [00:00<00:02, 101MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  21%|██        | 73.4M/347M [00:00<00:02, 117MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  27%|██▋       | 94.4M/347M [00:00<00:01, 127MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  33%|███▋       | 115M/347M [00:00<00:01, 135MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  39%|████▎      | 136M/347M [00:01<00:01, 140MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  45%|████▉      | 157M/347M [00:01<00:01, 142MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  51%|█████▋     | 178M/347M [00:01<00:01, 144MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  57%|██████▎    | 199M/347M [00:01<00:01, 145MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  63%|██████▉    | 220M/347M [00:01<00:00, 146MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  70%|███████▋   | 241M/347M [00:01<00:00, 143MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  76%|████████▎  | 262M/347M [00:01<00:00, 144MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  82%|████████▉  | 283M/347M [00:02<00:00, 146MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  88%|█████████▋ | 304M/347M [00:02<00:00, 147MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet:  94%|██████████▎| 325M/347M [00:02<00:00, 148MB/s]\u001b[A\r\n",
      "train-00015-of-00016.parquet: 100%|███████████| 347M/347M [00:02<00:00, 135MB/s]\r\n",
      "Downloading data: 100%|██████████████████████| 16/16 [00:44<00:00,  2.78s/files]\r\n",
      "Generating train split: 100%|████| 20491/20491 [00:20<00:00, 1015.43 examples/s]\r\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\r\n",
      "  warnings.warn(\r\n",
      "/kaggle/working/train.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\r\n",
      "/kaggle/working/train.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\r\n",
      "Checkpoint loaded: Resuming from Epoch 9, best_cider=2.0265265814067384Checkpoint loaded: Resuming from Epoch 9, best_cider=2.0265265814067384\r\n",
      "\r\n",
      "Epoch 1/9::   0%|                                      | 0/2050 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\r\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\r\n",
      "Epoch 1/9:: 100%|███████████████████████████| 2050/2050 [53:11<00:00,  1.56s/it]\r\n",
      "Epoch 1/9:: 100%|███████████████████████████| 2050/2050 [53:11<00:00,  1.56s/it]\r\n",
      "Validating epoch 1/9:: 100%|██████████████████| 257/257 [19:02<00:00,  4.45s/it]\r\n",
      "\r\n",
      "Epoch 1/9: train_loss=0.004759, val_loss=0.077499, val_cider=2.006018\r\n",
      "Epoch 2/9::   0%|                                      | 0/2050 [00:00<?, ?it/s]Epoch 1/9: train_loss=0.004759, val_loss=0.077499, val_cider=2.015932\r\n",
      "Epoch 2/9:: 100%|███████████████████████████| 2050/2050 [53:44<00:00,  1.57s/it]\r\n",
      "\r\n",
      "Validating epoch 2/9:: 100%|██████████████████| 257/257 [19:10<00:00,  4.48s/it]\r\n",
      "Validating epoch 2/9:: 100%|██████████████████| 257/257 [19:10<00:00,  4.48s/it]\r\n",
      "Epoch 2/9: train_loss=0.005013, val_loss=0.081351, val_cider=1.946909\r\n",
      "Epoch 3/9::   0%|                                      | 0/2050 [00:00<?, ?it/s]Epoch 2/9: train_loss=0.005013, val_loss=0.081351, val_cider=1.939903\r\n",
      "Epoch 3/9:: 100%|███████████████████████████| 2050/2050 [53:42<00:00,  1.57s/it]\r\n",
      "Epoch 3/9:: 100%|███████████████████████████| 2050/2050 [53:42<00:00,  1.57s/it]\r\n",
      "Validating epoch 3/9:: 100%|██████████████████| 257/257 [19:04<00:00,  4.46s/it]\r\n",
      "\r\n",
      "Epoch 3/9: train_loss=0.005960, val_loss=0.086078, val_cider=1.860147\r\n",
      "Epoch 4/9::   0%|                                      | 0/2050 [00:00<?, ?it/s]Epoch 3/9: train_loss=0.005960, val_loss=0.086078, val_cider=1.837945\r\n",
      "Epoch 4/9:: 100%|███████████████████████████| 2050/2050 [53:39<00:00,  1.57s/it]\r\n",
      "\r\n",
      "Validating epoch 4/9:: 100%|██████████████████| 257/257 [19:08<00:00,  4.47s/it]\r\n",
      "\r\n",
      "Epoch 4/9: train_loss=0.021643, val_loss=0.078415, val_cider=1.882276\r\n",
      "Epoch 5/9::   0%|                                      | 0/2050 [00:00<?, ?it/s]Epoch 4/9: train_loss=0.021643, val_loss=0.078415, val_cider=1.875354\r\n",
      "Epoch 5/9:: 100%|███████████████████████████| 2050/2050 [53:42<00:00,  1.57s/it]\r\n",
      "Epoch 5/9:: 100%|███████████████████████████| 2050/2050 [53:42<00:00,  1.57s/it]\r\n",
      "Validating epoch 5/9:: 100%|██████████████████| 257/257 [19:10<00:00,  4.48s/it]\r\n",
      "\r\n",
      "Epoch 5/9: train_loss=0.010613, val_loss=0.086269, val_cider=1.872667\r\n",
      "Epoch 6/9::   0%|                                      | 0/2050 [00:00<?, ?it/s]Epoch 5/9: train_loss=0.010613, val_loss=0.086269, val_cider=1.768199\r\n",
      "Epoch 6/9:: 100%|███████████████████████████| 2050/2050 [53:39<00:00,  1.57s/it]\r\n",
      "Epoch 6/9:: 100%|███████████████████████████| 2050/2050 [53:39<00:00,  1.57s/it]\r\n",
      "Validating epoch 6/9:: 100%|██████████████████| 257/257 [18:58<00:00,  4.43s/it]\r\n",
      "Validating epoch 6/9:: 100%|██████████████████| 257/257 [18:58<00:00,  4.43s/it]\r\n",
      "Epoch 6/9: train_loss=0.013690, val_loss=0.088299, val_cider=1.746913\r\n",
      "Epoch 7/9::   0%|                                      | 0/2050 [00:00<?, ?it/s]Epoch 6/9: train_loss=0.013690, val_loss=0.088299, val_cider=1.639491\r\n",
      "Epoch 7/9:: 100%|███████████████████████████| 2050/2050 [53:41<00:00,  1.57s/it]\r\n",
      "Epoch 7/9:: 100%|███████████████████████████| 2050/2050 [53:41<00:00,  1.57s/it]\r\n",
      "Validating epoch 7/9:: 100%|██████████████████| 257/257 [19:00<00:00,  4.44s/it]\r\n",
      "Validating epoch 7/9:: 100%|██████████████████| 257/257 [19:00<00:00,  4.44s/it]\r\n",
      "Epoch 7/9: train_loss=0.041219, val_loss=0.080877, val_cider=1.780495\r\n",
      "Epoch 8/9::   0%|                                      | 0/2050 [00:00<?, ?it/s]Epoch 7/9: train_loss=0.041219, val_loss=0.080877, val_cider=1.778743\r\n",
      "Epoch 8/9:: 100%|███████████████████████████| 2050/2050 [53:50<00:00,  1.58s/it]\r\n",
      "Epoch 8/9:: 100%|███████████████████████████| 2050/2050 [53:51<00:00,  1.58s/it]\r\n",
      "Validating epoch 8/9:: 100%|██████████████████| 257/257 [19:00<00:00,  4.44s/it]\r\n",
      "Validating epoch 8/9:: 100%|██████████████████| 257/257 [19:00<00:00,  4.44s/it]\r\n",
      "Epoch 8/9: train_loss=0.015890, val_loss=0.086769, val_cider=1.714658\r\n",
      "Epoch 9/9::   0%|                                      | 0/2050 [00:00<?, ?it/s]Epoch 8/9: train_loss=0.015890, val_loss=0.086769, val_cider=1.698773\r\n",
      "Epoch 9/9:: 100%|███████████████████████████| 2050/2050 [53:49<00:00,  1.58s/it]\r\n",
      "Epoch 9/9:: 100%|███████████████████████████| 2050/2050 [53:49<00:00,  1.58s/it]\r\n",
      "Validating epoch 9/9:: 100%|██████████████████| 257/257 [19:03<00:00,  4.45s/it]\r\n",
      "Validating epoch 9/9:: 100%|██████████████████| 257/257 [19:03<00:00,  4.45s/it]\r\n",
      "Epoch 9/9: train_loss=0.014588, val_loss=0.087400, val_cider=1.782616\r\n",
      "Epoch 9/9: train_loss=0.014588, val_loss=0.087400, val_cider=1.747748\r\n",
      "Last checkpoint saved.\r\n",
      "Last checkpoint saved.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ▁▁▁▄▂▃█▃▃\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_cider █▇▄▅▅▂▃▁▃\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ▁▃▇▂▇█▃▇▇\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.01459\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_cider 1.78262\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.0874\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/wandb/offline-run-20250406_002754-unfreeze_vit\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20250406_002754-unfreeze_vit/logs\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ▁▁▁▄▂▃█▃▃\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_cider █▇▅▅▃▁▄▂▃\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ▁▃▇▂▇█▃▇▇\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.01459\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  val_cider 1.74775\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.0874\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/wandb/offline-run-20250406_002754-unfreeze_vit\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20250406_002754-unfreeze_vit/logs\u001b[0m\r\n",
      "[rank0]:[W406 11:24:52.849300109 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\r\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch train.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 292956,
     "modelInstanceId": 271969,
     "sourceId": 322768,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39490.378157,
   "end_time": "2025-04-06T11:25:00.654938",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-06T00:26:50.276781",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
